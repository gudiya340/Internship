{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5321a2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\yashika\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yashika\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yashika\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7057c741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\yashika\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yashika\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yashika\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yashika\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yashika\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d775da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31573957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751a5d39",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c87f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a850fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(url)\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bb21467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Free Encyclopedia',\n",
       " 'English',\n",
       " 'Русский',\n",
       " '日本語',\n",
       " 'Deutsch',\n",
       " 'Français',\n",
       " 'Español',\n",
       " 'Italiano',\n",
       " '中文',\n",
       " 'فارسی',\n",
       " 'Polski',\n",
       " '\\n\\nDownload Wikipedia for Android or iOS\\n\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers= []\n",
    "for i in soup.find_all ('strong'):\n",
    "    headers.append(i.text)\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "361569c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Free Encyclopedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Русский</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>日本語</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deutsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Français</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Español</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Italiano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>中文</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>فارسی</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Polski</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Headers\n",
       "0   The Free Encyclopedia\n",
       "1                 English\n",
       "2                 Русский\n",
       "3                     日本語\n",
       "4                 Deutsch\n",
       "5                Français\n",
       "6                 Español\n",
       "7                Italiano\n",
       "8                      中文\n",
       "9                   فارسی\n",
       "10                 Polski"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame({'Headers':headers})\n",
    "df.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b85e4",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "175484a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.imdb.com/list/ls055386972/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b483bd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Godfather',\n",
       " \"Schindler's List\",\n",
       " '12 Angry Men',\n",
       " 'La vita è bella',\n",
       " 'Il buono, il brutto, il cattivo',\n",
       " 'The Shawshank Redemption',\n",
       " 'The Pursuit of Happyness',\n",
       " 'Shichinin no samurai',\n",
       " 'The Intouchables',\n",
       " 'Central do Brasil',\n",
       " 'Requiem for a Dream',\n",
       " 'A Beautiful Mind',\n",
       " \"Hachi: A Dog's Tale\",\n",
       " 'Taken',\n",
       " 'Yeopgijeogin geunyeo',\n",
       " 'Amores perros',\n",
       " 'The Shining',\n",
       " 'Apocalypto',\n",
       " 'Gladiator',\n",
       " 'Cast Away',\n",
       " 'The Dark Knight',\n",
       " 'The Pianist',\n",
       " 'Titanic',\n",
       " 'Bin-jip',\n",
       " 'Braveheart',\n",
       " \"It's a Wonderful Life\",\n",
       " 'Bom yeoreum gaeul gyeoul geurigo bom',\n",
       " 'Alien',\n",
       " 'Salinui chueok',\n",
       " 'Vozvrashchenie',\n",
       " 'Ang-ma-reul bo-at-da',\n",
       " 'Bacheha-Ye aseman',\n",
       " 'Jodaeiye Nader az Simin',\n",
       " 'The Sixth Sense',\n",
       " 'Nae meorisokui jiwoogae',\n",
       " 'Okuribito',\n",
       " 'Wo de fu qin mu qin',\n",
       " 'Saving Private Ryan',\n",
       " 'The Bridge on the River Kwai',\n",
       " 'Ben-Hur',\n",
       " 'The Exorcist',\n",
       " 'El secreto de sus ojos',\n",
       " 'Léon',\n",
       " 'The Green Mile',\n",
       " 'Gran Torino',\n",
       " 'Kill Bill: Vol. 1',\n",
       " 'Jurassic Park',\n",
       " 'Terminator 2: Judgment Day',\n",
       " 'Back to the Future',\n",
       " 'Finding Nemo']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = []\n",
    "for i in soup.find_all('h3', class_=\"lister-item-header\"):\n",
    "    name.append(i.text.split('\\n')[2])\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "845726ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '9',\n",
       " '9',\n",
       " '8.6',\n",
       " '8.8',\n",
       " '9.3',\n",
       " '8',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '7.8',\n",
       " '8',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '7.8',\n",
       " '8.5',\n",
       " '7.8',\n",
       " '9',\n",
       " '8.5',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '8.4',\n",
       " '8.6',\n",
       " '8',\n",
       " '8.5',\n",
       " '8.1',\n",
       " '7.9',\n",
       " '7.8',\n",
       " '8.2',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8',\n",
       " '7.8',\n",
       " '8.6',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.2',\n",
       " '8.5',\n",
       " '8.6',\n",
       " '8.1',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.6',\n",
       " '8.5',\n",
       " '8.2']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = []\n",
    "for i in soup.find_all('div', class_=\"ipl-rating-star small\"):\n",
    "    ratings.append(i.text.split('\\n')[8])\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af483e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1972)',\n",
       " '(1993)',\n",
       " '(1957)',\n",
       " '(1997)',\n",
       " '(1966)',\n",
       " '(1994)',\n",
       " '(2006)',\n",
       " '(1954)',\n",
       " '(2011)',\n",
       " '(1998)',\n",
       " '(2000)',\n",
       " '(2001)',\n",
       " '(2009)',\n",
       " '(I) (2008)',\n",
       " '(2001)',\n",
       " '(2000)',\n",
       " '(1980)',\n",
       " '(2006)',\n",
       " '(2000)',\n",
       " '(2000)',\n",
       " '(2008)',\n",
       " '(2002)',\n",
       " '(1997)',\n",
       " '(2004)',\n",
       " '(1995)',\n",
       " '(1946)',\n",
       " '(2003)',\n",
       " '(1979)',\n",
       " '(2003)',\n",
       " '(2003)',\n",
       " '(2010)',\n",
       " '(1997)',\n",
       " '(2011)',\n",
       " '(1999)',\n",
       " '(2004)',\n",
       " '(2008)',\n",
       " '(1999)',\n",
       " '(1998)',\n",
       " '(1957)',\n",
       " '(1959)',\n",
       " '(1973)',\n",
       " '(2009)',\n",
       " '(1994)',\n",
       " '(1999)',\n",
       " '(2008)',\n",
       " '(2003)',\n",
       " '(1993)',\n",
       " '(1991)',\n",
       " '(1985)',\n",
       " '(2003)']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = []\n",
    "for i in soup.find_all('span', class_= \"lister-item-year text-muted unbold\"):\n",
    "    year.append(i.text)\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d435982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>9</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>La vita è bella</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Il buono, il brutto, il cattivo</td>\n",
       "      <td>8.8</td>\n",
       "      <td>(1966)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Pursuit of Happyness</td>\n",
       "      <td>8</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shichinin no samurai</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1954)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Intouchables</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Central do Brasil</td>\n",
       "      <td>8</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Requiem for a Dream</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A Beautiful Mind</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hachi: A Dog's Tale</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Taken</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(I) (2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Yeopgijeogin geunyeo</td>\n",
       "      <td>8</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Amores perros</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Shining</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Apocalypto</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gladiator</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cast Away</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The Pianist</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>7.9</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Bin-jip</td>\n",
       "      <td>7.9</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Braveheart</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>It's a Wonderful Life</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1946)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Bom yeoreum gaeul gyeoul geurigo bom</td>\n",
       "      <td>8</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Alien</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Salinui chueok</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Vozvrashchenie</td>\n",
       "      <td>7.9</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Ang-ma-reul bo-at-da</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Bacheha-Ye aseman</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Jodaeiye Nader az Simin</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>The Sixth Sense</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Nae meorisokui jiwoogae</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Okuribito</td>\n",
       "      <td>8</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Wo de fu qin mu qin</td>\n",
       "      <td>7.8</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Saving Private Ryan</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The Bridge on the River Kwai</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Ben-Hur</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The Exorcist</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1973)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>El secreto de sus ojos</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Léon</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>The Green Mile</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Gran Torino</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Kill Bill: Vol. 1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Jurassic Park</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Back to the Future</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Finding Nemo</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Name Ratings Year of Release\n",
       "0                          The Godfather     9.2          (1972)\n",
       "1                       Schindler's List       9          (1993)\n",
       "2                           12 Angry Men       9          (1957)\n",
       "3                        La vita è bella     8.6          (1997)\n",
       "4        Il buono, il brutto, il cattivo     8.8          (1966)\n",
       "5               The Shawshank Redemption     9.3          (1994)\n",
       "6               The Pursuit of Happyness       8          (2006)\n",
       "7                   Shichinin no samurai     8.6          (1954)\n",
       "8                       The Intouchables     8.5          (2011)\n",
       "9                      Central do Brasil       8          (1998)\n",
       "10                   Requiem for a Dream     8.3          (2000)\n",
       "11                      A Beautiful Mind     8.2          (2001)\n",
       "12                   Hachi: A Dog's Tale     8.1          (2009)\n",
       "13                                 Taken     7.8      (I) (2008)\n",
       "14                  Yeopgijeogin geunyeo       8          (2001)\n",
       "15                         Amores perros     8.1          (2000)\n",
       "16                           The Shining     8.4          (1980)\n",
       "17                            Apocalypto     7.8          (2006)\n",
       "18                             Gladiator     8.5          (2000)\n",
       "19                             Cast Away     7.8          (2000)\n",
       "20                       The Dark Knight       9          (2008)\n",
       "21                           The Pianist     8.5          (2002)\n",
       "22                               Titanic     7.9          (1997)\n",
       "23                               Bin-jip     7.9          (2004)\n",
       "24                            Braveheart     8.4          (1995)\n",
       "25                 It's a Wonderful Life     8.6          (1946)\n",
       "26  Bom yeoreum gaeul gyeoul geurigo bom       8          (2003)\n",
       "27                                 Alien     8.5          (1979)\n",
       "28                        Salinui chueok     8.1          (2003)\n",
       "29                        Vozvrashchenie     7.9          (2003)\n",
       "30                  Ang-ma-reul bo-at-da     7.8          (2010)\n",
       "31                     Bacheha-Ye aseman     8.2          (1997)\n",
       "32               Jodaeiye Nader az Simin     8.3          (2011)\n",
       "33                       The Sixth Sense     8.2          (1999)\n",
       "34               Nae meorisokui jiwoogae     8.1          (2004)\n",
       "35                             Okuribito       8          (2008)\n",
       "36                   Wo de fu qin mu qin     7.8          (1999)\n",
       "37                   Saving Private Ryan     8.6          (1998)\n",
       "38          The Bridge on the River Kwai     8.2          (1957)\n",
       "39                               Ben-Hur     8.1          (1959)\n",
       "40                          The Exorcist     8.1          (1973)\n",
       "41                El secreto de sus ojos     8.2          (2009)\n",
       "42                                  Léon     8.5          (1994)\n",
       "43                        The Green Mile     8.6          (1999)\n",
       "44                           Gran Torino     8.1          (2008)\n",
       "45                     Kill Bill: Vol. 1     8.2          (2003)\n",
       "46                         Jurassic Park     8.2          (1993)\n",
       "47            Terminator 2: Judgment Day     8.6          (1991)\n",
       "48                    Back to the Future     8.5          (1985)\n",
       "49                          Finding Nemo     8.2          (2003)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Name':name, 'Ratings':ratings, 'Year of Release':year})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24dc69b",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24cccba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b254b2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['      Ramayana: The Legend of Prince Rama',\n",
       " '      Rocketry: The Nambi Effect',\n",
       " '      Nayakan',\n",
       " '      Gol Maal',\n",
       " '      Anbe Sivam',\n",
       " '      777 Charlie',\n",
       " '      Jai Bhim',\n",
       " '      Pariyerum Perumal',\n",
       " '      3 Idiots',\n",
       " '      Apur Sansar',\n",
       " '      Manichitrathazhu',\n",
       " '      #Home',\n",
       " '      Soorarai Pottru',\n",
       " '      Black Friday',\n",
       " '      Kumbalangi Nights',\n",
       " '      C/o Kancharapalem',\n",
       " '      Taare Zameen Par',\n",
       " '      Kireedam',\n",
       " '      Dangal',\n",
       " '      Kaithi',\n",
       " '      Jersey',\n",
       " '      96',\n",
       " '      Maya Bazaar',\n",
       " '      Natsamrat',\n",
       " '      Sita Ramam',\n",
       " '      Drishyam 2',\n",
       " '      Asuran',\n",
       " '      Thevar Magan',\n",
       " '      Visaaranai',\n",
       " '      Sarpatta Parambarai',\n",
       " '      Thalapathi',\n",
       " '      Pather Panchali',\n",
       " '      Nadodikkattu',\n",
       " '      Drishyam',\n",
       " '      Jaane Bhi Do Yaaro',\n",
       " '      Thani Oruvan',\n",
       " '      Sardar Udham',\n",
       " '      Aparajito',\n",
       " '      Vada Chennai',\n",
       " '      Khosla Ka Ghosla!',\n",
       " '      Anniyan',\n",
       " '      Ratsasan',\n",
       " '      Chupke Chupke',\n",
       " '      Gangs of Wasseypur',\n",
       " '      Peranbu',\n",
       " '      Drishyam',\n",
       " '      Bangalore Days',\n",
       " '      Mahanati',\n",
       " '      Satya',\n",
       " '      Premam',\n",
       " '      Agent Sai Srinivasa Athreya',\n",
       " '      Devasuram',\n",
       " '      Super Deluxe',\n",
       " '      Bhaag Milkha Bhaag',\n",
       " '      Tumbbad',\n",
       " '      Andhadhun',\n",
       " '      Vikram Vedha',\n",
       " '      Guide',\n",
       " '      Chithram',\n",
       " '      Zindagi Na Milegi Dobara',\n",
       " '      Chhichhore',\n",
       " '      Sairat',\n",
       " '      Kannathil Muthamittal',\n",
       " '      Vikram',\n",
       " '      Shahid',\n",
       " '      Iruvar',\n",
       " '      Paan Singh Tomar',\n",
       " '      Aruvi',\n",
       " '      Swades: We, the People',\n",
       " '      Spadikam',\n",
       " '      Munna Bhai M.B.B.S.',\n",
       " '      Chak De! India',\n",
       " '      Uri: The Surgical Strike',\n",
       " '      Pyaasa',\n",
       " '      Mudhalvan',\n",
       " '      Black',\n",
       " '      Jo Jeeta Wohi Sikandar',\n",
       " '      Hera Pheri',\n",
       " '      Papanasam',\n",
       " '      Lagaan: Once Upon a Time in India',\n",
       " '      Pudhu Pettai',\n",
       " '      Dhuruvangal Pathinaaru',\n",
       " '      PK',\n",
       " '      Drishyam 2',\n",
       " '      Mandela',\n",
       " '      Queen',\n",
       " '      Article 15',\n",
       " '      Talvar',\n",
       " '      OMG: Oh My God!',\n",
       " '      Soodhu Kavvum',\n",
       " '      Sarfarosh',\n",
       " '      Sholay',\n",
       " '      Udaan',\n",
       " '      Barfi!',\n",
       " '      Jigarthanda',\n",
       " '      Kaakkaa Muttai',\n",
       " '      The Legend of Bhagat Singh',\n",
       " '      Ustad Hotel',\n",
       " '      Theeran Adhigaaram Ondru',\n",
       " '      Baahubali 2: The Conclusion',\n",
       " '      Rang De Basanti',\n",
       " '      Jana Gana Mana',\n",
       " '      Angoor',\n",
       " '      Kahaani',\n",
       " '      Masaan',\n",
       " '      Maheshinte Prathikaaram',\n",
       " '      A Wednesday',\n",
       " '      Virumandi',\n",
       " '      Dil Chahta Hai',\n",
       " '      Baasha',\n",
       " '      Shershaah',\n",
       " '      Lage Raho Munna Bhai',\n",
       " '      Iqbal',\n",
       " '      Pink',\n",
       " '      Roja',\n",
       " '      Pithamagan',\n",
       " '      Anand',\n",
       " '      Nil Battey Sannata',\n",
       " '      Lucia',\n",
       " '      Kantara',\n",
       " '      Kaun Pravin Tambe?',\n",
       " '      Charulata',\n",
       " '      Bajrangi Bhaijaan',\n",
       " '      Omkara',\n",
       " '      Oru Vadakkan Veeragatha',\n",
       " '      Section 375',\n",
       " '      Bommarillu',\n",
       " '      Alai Payuthey',\n",
       " '      Bombay',\n",
       " '      K.G.F: Chapter 1',\n",
       " '      Rangasthalam',\n",
       " '      Indian',\n",
       " '      Dilwale Dulhania Le Jayenge',\n",
       " '      Haider',\n",
       " '      Athadu',\n",
       " '      Mughal-E-Azam',\n",
       " '      The Great Indian Kitchen',\n",
       " '      Andaz Apna Apna',\n",
       " '      Special Chabbis',\n",
       " '      Maqbool',\n",
       " '      Vaaranam Aayiram',\n",
       " '      Padayappa',\n",
       " '      Thadam',\n",
       " '      Maanaadu',\n",
       " '      Gulaal',\n",
       " '      Pelli Choopulu',\n",
       " '      K.G.F: Chapter 2',\n",
       " '      Ulidavaru Kandanthe',\n",
       " '      Deewaar',\n",
       " '      Company',\n",
       " '      Vaastav: The Reality',\n",
       " '      Ugly',\n",
       " '      Badhaai ho',\n",
       " '      Naduvula Konjam Pakkatha Kaanom',\n",
       " '      Padosan',\n",
       " '      Gully Boy',\n",
       " '      Kshanam',\n",
       " '      Aadukalam',\n",
       " '      Evaru',\n",
       " '      My Name Is Khan',\n",
       " '      Nayattu',\n",
       " '      Dev.D',\n",
       " '      Maanagaram',\n",
       " '      Major',\n",
       " '      Thondimuthalum Dhriksakshiyum',\n",
       " '      Pranchiyettan and the Saint',\n",
       " '      Kal Ho Naa Ho',\n",
       " '      Baishe Srabon',\n",
       " '      Garuda Gamana Vrishabha Vahana',\n",
       " '      Jab We Met',\n",
       " '      Take Off',\n",
       " '      Manjhi: The Mountain Man',\n",
       " '      Ayyappanum Koshiyum',\n",
       " '      Ship of Theseus',\n",
       " '      Mukkabaaz',\n",
       " '      Charlie',\n",
       " '      Border',\n",
       " '      Deiva Thirumagal',\n",
       " '      Vedam',\n",
       " '      M.S. Dhoni: The Untold Story',\n",
       " '      Dil Bechara',\n",
       " '      Bãhubali: The Beginning',\n",
       " '      Salaam Bombay!',\n",
       " '      Arjun Reddy',\n",
       " '      Padman',\n",
       " '      Karnan',\n",
       " '      Baby',\n",
       " '      Ankhon Dekhi',\n",
       " '      Jalsaghar',\n",
       " '      Kirik Party',\n",
       " '      Vinnaithaandi Varuvaayaa',\n",
       " '      Love Today',\n",
       " '      Super 30',\n",
       " '      The Tashkent Files',\n",
       " '      Malik',\n",
       " '      Pizza',\n",
       " '      Hindi Medium',\n",
       " '      Hridayam',\n",
       " '      Android Kunjappan Version 5.25',\n",
       " '      English Vinglish',\n",
       " '      Lakshya',\n",
       " '      Johnny Gaddaar',\n",
       " '      Hey Ram',\n",
       " '      Dor',\n",
       " '      Memories',\n",
       " '      Joseph',\n",
       " '      Airlift',\n",
       " '      Anjaam Pathiraa',\n",
       " '      RRR (Rise Roar Revolt)',\n",
       " '      Kaakha..Kaakha: The Police',\n",
       " '      Gangaajal',\n",
       " '      Okkadu',\n",
       " '      Thuppakki',\n",
       " '      Pokiri',\n",
       " '      The Lunchbox',\n",
       " '      Vettaiyaadu Vilaiyaadu',\n",
       " '      Ghilli',\n",
       " '      Ab Tak Chhappan',\n",
       " '      Mumbai Police',\n",
       " '      Manam',\n",
       " '      Unnaipol Oruvan',\n",
       " '      Veer-Zaara',\n",
       " '      RangiTaranga',\n",
       " '      Kaththi',\n",
       " '      Vicky Donor',\n",
       " '      Angamaly Diaries',\n",
       " '      Oopiri',\n",
       " '      Mother India',\n",
       " '      Secret Superstar',\n",
       " '      Stanley Ka Dabba',\n",
       " '      Thulladha Manamum Thullum',\n",
       " '      Nayak: The Real Hero',\n",
       " '      Rock On!!',\n",
       " '      Mr. India',\n",
       " '      Mimi',\n",
       " '      Udta Punjab',\n",
       " '      Sonchiriya',\n",
       " '      Aayirathil Oruvan',\n",
       " '      Oru CBI Diary Kurippu',\n",
       " '      Badla',\n",
       " '      Happy Days',\n",
       " '      Dasvidaniya',\n",
       " '      Raazi',\n",
       " '      Kai po che!',\n",
       " '      Poove Unakkaga',\n",
       " '      Dia',\n",
       " '      Minnal Murali',\n",
       " '      Thiruchitrambalam',\n",
       " '      Goodachari',\n",
       " '      Velaiilla Pattadhari']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_name = []\n",
    "for i in soup.find_all('td', class_=\"titleColumn\"):\n",
    "    movie_name.append(i.text.split('\\n')[2])\n",
    "movie_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ad9b809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(1993)',\n",
       " '(2022)',\n",
       " '(1987)',\n",
       " '(1979)',\n",
       " '(2003)',\n",
       " '(2022)',\n",
       " '(2021)',\n",
       " '(2018)',\n",
       " '(2009)',\n",
       " '(1959)',\n",
       " '(1993)',\n",
       " '(2021)',\n",
       " '(2020)',\n",
       " '(2004)',\n",
       " '(2019)',\n",
       " '(2018)',\n",
       " '(2007)',\n",
       " '(1989)',\n",
       " '(2016)',\n",
       " '(2019)',\n",
       " '(2019)',\n",
       " '(2018)',\n",
       " '(1957)',\n",
       " '(2016)',\n",
       " '(2022)',\n",
       " '(2021)',\n",
       " '(2019)',\n",
       " '(1992)',\n",
       " '(2015)',\n",
       " '(2021)',\n",
       " '(1991)',\n",
       " '(1955)',\n",
       " '(1987)',\n",
       " '(2013)',\n",
       " '(1983)',\n",
       " '(2015)',\n",
       " '(2021)',\n",
       " '(1956)',\n",
       " '(2018)',\n",
       " '(2006)',\n",
       " '(2005)',\n",
       " '(2018)',\n",
       " '(1975)',\n",
       " '(2012)',\n",
       " '(2018)',\n",
       " '(2015)',\n",
       " '(2014)',\n",
       " '(2018)',\n",
       " '(1998)',\n",
       " '(2015)',\n",
       " '(2019)',\n",
       " '(1993)',\n",
       " '(2019)',\n",
       " '(2013)',\n",
       " '(2018)',\n",
       " '(2018)',\n",
       " '(2017)',\n",
       " '(1965)',\n",
       " '(1988)',\n",
       " '(2011)',\n",
       " '(2019)',\n",
       " '(2016)',\n",
       " '(2002)',\n",
       " '(2022)',\n",
       " '(2012)',\n",
       " '(1997)',\n",
       " '(2012)',\n",
       " '(2016)',\n",
       " '(2004)',\n",
       " '(1995)',\n",
       " '(2003)',\n",
       " '(2007)',\n",
       " '(2019)',\n",
       " '(1957)',\n",
       " '(1999)',\n",
       " '(2005)',\n",
       " '(1992)',\n",
       " '(2000)',\n",
       " '(2015)',\n",
       " '(2001)',\n",
       " '(2006)',\n",
       " '(2016)',\n",
       " '(2014)',\n",
       " '(2022)',\n",
       " '(2021)',\n",
       " '(2013)',\n",
       " '(2019)',\n",
       " '(2015)',\n",
       " '(2012)',\n",
       " '(2013)',\n",
       " '(1999)',\n",
       " '(1975)',\n",
       " '(2010)',\n",
       " '(2012)',\n",
       " '(2014)',\n",
       " '(2014)',\n",
       " '(2002)',\n",
       " '(2012)',\n",
       " '(2017)',\n",
       " '(2017)',\n",
       " '(2006)',\n",
       " '(2022)',\n",
       " '(1982)',\n",
       " '(2012)',\n",
       " '(2015)',\n",
       " '(2016)',\n",
       " '(2008)',\n",
       " '(2004)',\n",
       " '(2001)',\n",
       " '(1995)',\n",
       " '(2021)',\n",
       " '(2006)',\n",
       " '(2005)',\n",
       " '(2016)',\n",
       " '(1992)',\n",
       " '(2003)',\n",
       " '(1971)',\n",
       " '(2015)',\n",
       " '(2013)',\n",
       " '(2022)',\n",
       " '(2022)',\n",
       " '(1964)',\n",
       " '(2015)',\n",
       " '(2006)',\n",
       " '(1989)',\n",
       " '(2019)',\n",
       " '(2006)',\n",
       " '(2000)',\n",
       " '(1995)',\n",
       " '(2018)',\n",
       " '(2018)',\n",
       " '(1996)',\n",
       " '(1995)',\n",
       " '(2014)',\n",
       " '(2005)',\n",
       " '(1960)',\n",
       " '(2021)',\n",
       " '(1994)',\n",
       " '(2013)',\n",
       " '(2003)',\n",
       " '(2008)',\n",
       " '(1999)',\n",
       " '(2019)',\n",
       " '(2021)',\n",
       " '(2009)',\n",
       " '(2016)',\n",
       " '(2022)',\n",
       " '(2014)',\n",
       " '(1975)',\n",
       " '(2002)',\n",
       " '(1999)',\n",
       " '(2013)',\n",
       " '(2018)',\n",
       " '(2012)',\n",
       " '(1968)',\n",
       " '(2019)',\n",
       " '(2016)',\n",
       " '(2011)',\n",
       " '(2019)',\n",
       " '(2010)',\n",
       " '(2021)',\n",
       " '(2009)',\n",
       " '(2017)',\n",
       " '(2022)',\n",
       " '(2017)',\n",
       " '(2010)',\n",
       " '(2003)',\n",
       " '(2011)',\n",
       " '(2021)',\n",
       " '(2007)',\n",
       " '(2017)',\n",
       " '(2015)',\n",
       " '(2020)',\n",
       " '(2012)',\n",
       " '(2017)',\n",
       " '(2015)',\n",
       " '(1997)',\n",
       " '(2011)',\n",
       " '(2010)',\n",
       " '(2016)',\n",
       " '(2020)',\n",
       " '(2015)',\n",
       " '(1988)',\n",
       " '(2017)',\n",
       " '(2018)',\n",
       " '(2021)',\n",
       " '(2015)',\n",
       " '(2013)',\n",
       " '(1958)',\n",
       " '(2016)',\n",
       " '(2010)',\n",
       " '(2022)',\n",
       " '(2019)',\n",
       " '(2019)',\n",
       " '(2021)',\n",
       " '(2012)',\n",
       " '(2017)',\n",
       " '(2022)',\n",
       " '(2019)',\n",
       " '(2012)',\n",
       " '(2004)',\n",
       " '(2007)',\n",
       " '(2000)',\n",
       " '(2006)',\n",
       " '(2013)',\n",
       " '(2018)',\n",
       " '(2016)',\n",
       " '(2020)',\n",
       " '(2022)',\n",
       " '(2003)',\n",
       " '(2003)',\n",
       " '(2003)',\n",
       " '(2012)',\n",
       " '(2006)',\n",
       " '(2013)',\n",
       " '(2006)',\n",
       " '(2004)',\n",
       " '(2004)',\n",
       " '(2013)',\n",
       " '(2014)',\n",
       " '(2009)',\n",
       " '(2004)',\n",
       " '(2015)',\n",
       " '(2014)',\n",
       " '(2012)',\n",
       " '(2017)',\n",
       " '(2016)',\n",
       " '(1957)',\n",
       " '(2017)',\n",
       " '(2011)',\n",
       " '(1999)',\n",
       " '(2001)',\n",
       " '(2008)',\n",
       " '(1987)',\n",
       " '(2021)',\n",
       " '(2016)',\n",
       " '(2019)',\n",
       " '(2010)',\n",
       " '(1988)',\n",
       " '(2019)',\n",
       " '(2007)',\n",
       " '(2008)',\n",
       " '(2018)',\n",
       " '(2013)',\n",
       " '(1996)',\n",
       " '(2020)',\n",
       " '(2021)',\n",
       " '(2022)',\n",
       " '(2018)',\n",
       " '(2014)']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "release= []\n",
    "for i in soup.find_all('td', class_=\"titleColumn\"):\n",
    "    release.append(i.text.split('\\n')[3])\n",
    "release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2354be7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8.6',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.1',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '8.0',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.9',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.8',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.7',\n",
       " '7.6']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate = []\n",
    "for i in soup.find_all('td', class_=\"ratingColumn imdbRating\"):\n",
    "    rate.append(i.text.split('\\n')[1])\n",
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c05b8969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Year Of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ramayana: The Legend of Prince Rama</td>\n",
       "      <td>8.6</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rocketry: The Nambi Effect</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gol Maal</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>777 Charlie</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Apur Sansar</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manichitrathazhu</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#Home</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Soorarai Pottru</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2020)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Black Friday</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kumbalangi Nights</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C/o Kancharapalem</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kireedam</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1989)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dangal</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2016)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kaithi</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jersey</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>96</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Maya Bazaar</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Natsamrat</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2016)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sita Ramam</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Drishyam 2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Asuran</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Thevar Magan</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Visaaranai</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sarpatta Parambarai</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Thalapathi</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Nadodikkattu</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Jaane Bhi Do Yaaro</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1983)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Thani Oruvan</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sardar Udham</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Aparajito</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1956)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Vada Chennai</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Khosla Ka Ghosla!</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Anniyan</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(2005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ratsasan</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Chupke Chupke</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gangs of Wasseypur</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Peranbu</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Drishyam</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bangalore Days</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Mahanati</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Satya</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Premam</td>\n",
       "      <td>8.1</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Name Ratings Year Of Release\n",
       "0         Ramayana: The Legend of Prince Rama     8.6          (1993)\n",
       "1                  Rocketry: The Nambi Effect     8.4          (2022)\n",
       "2                                     Nayakan     8.4          (1987)\n",
       "3                                    Gol Maal     8.4          (1979)\n",
       "4                                  Anbe Sivam     8.4          (2003)\n",
       "5                                 777 Charlie     8.4          (2022)\n",
       "6                                    Jai Bhim     8.4          (2021)\n",
       "7                           Pariyerum Perumal     8.4          (2018)\n",
       "8                                    3 Idiots     8.4          (2009)\n",
       "9                                 Apur Sansar     8.4          (1959)\n",
       "10                           Manichitrathazhu     8.4          (1993)\n",
       "11                                      #Home     8.3          (2021)\n",
       "12                            Soorarai Pottru     8.3          (2020)\n",
       "13                               Black Friday     8.3          (2004)\n",
       "14                          Kumbalangi Nights     8.3          (2019)\n",
       "15                          C/o Kancharapalem     8.3          (2018)\n",
       "16                           Taare Zameen Par     8.3          (2007)\n",
       "17                                   Kireedam     8.3          (1989)\n",
       "18                                     Dangal     8.3          (2016)\n",
       "19                                     Kaithi     8.3          (2019)\n",
       "20                                     Jersey     8.3          (2019)\n",
       "21                                         96     8.3          (2018)\n",
       "22                                Maya Bazaar     8.2          (1957)\n",
       "23                                  Natsamrat     8.2          (2016)\n",
       "24                                 Sita Ramam     8.2          (2022)\n",
       "25                                 Drishyam 2     8.2          (2021)\n",
       "26                                     Asuran     8.2          (2019)\n",
       "27                               Thevar Magan     8.2          (1992)\n",
       "28                                 Visaaranai     8.2          (2015)\n",
       "29                        Sarpatta Parambarai     8.2          (2021)\n",
       "30                                 Thalapathi     8.2          (1991)\n",
       "31                            Pather Panchali     8.2          (1955)\n",
       "32                               Nadodikkattu     8.2          (1987)\n",
       "33                                   Drishyam     8.2          (2013)\n",
       "34                         Jaane Bhi Do Yaaro     8.2          (1983)\n",
       "35                               Thani Oruvan     8.2          (2015)\n",
       "36                               Sardar Udham     8.2          (2021)\n",
       "37                                  Aparajito     8.2          (1956)\n",
       "38                               Vada Chennai     8.2          (2018)\n",
       "39                          Khosla Ka Ghosla!     8.2          (2006)\n",
       "40                                    Anniyan     8.2          (2005)\n",
       "41                                   Ratsasan     8.1          (2018)\n",
       "42                              Chupke Chupke     8.1          (1975)\n",
       "43                         Gangs of Wasseypur     8.1          (2012)\n",
       "44                                    Peranbu     8.1          (2018)\n",
       "45                                   Drishyam     8.1          (2015)\n",
       "46                             Bangalore Days     8.1          (2014)\n",
       "47                                   Mahanati     8.1          (2018)\n",
       "48                                      Satya     8.1          (1998)\n",
       "49                                     Premam     8.1          (2015)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Name':movie_name, 'Ratings': rate, 'Year Of Release': release})\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1aba06",
   "metadata": {},
   "source": [
    "Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d72fe4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e767896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shri Ram Nath Kovind (birth - 1945)',\n",
       " 'Shri Pranab Mukherjee (1935-2020)',\n",
       " 'Smt Pratibha Devisingh Patil (birth - 1934)',\n",
       " 'DR. A.P.J. Abdul Kalam (1931-2015)',\n",
       " 'Shri K. R. Narayanan (1920 - 2005)',\n",
       " 'Dr Shankar Dayal Sharma (1918-1999)',\n",
       " 'Shri R Venkataraman (1910-2009)',\n",
       " 'Giani Zail Singh (1916-1994)',\n",
       " 'Shri Neelam Sanjiva Reddy (1913-1996)',\n",
       " 'Dr. Fakhruddin Ali Ahmed (1905-1977)',\n",
       " 'Shri Varahagiri Venkata Giri (1894-1980)',\n",
       " 'Dr. Zakir Husain (1897-1969)',\n",
       " 'Dr. Sarvepalli Radhakrishnan (1888-1975)',\n",
       " 'Dr. Rajendra Prasad (1884-1963) ']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "for i in soup.find_all('div',class_=\"presidentListing\"):\n",
    "    names.append(i.text.split('\\n')[1])\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3b8fd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Term of Office: 25 July, 2017 to 25 July, 2022 ',\n",
       " 'Term of Office: 25 July, 2012 to 25 July, 2017 ',\n",
       " 'Term of Office: 25 July, 2007 to 25 July, 2012 ',\n",
       " 'Term of Office: 25 July, 2002 to 25 July, 2007 ',\n",
       " 'Term of Office: 25 July, 1997 to 25 July, 2002 ',\n",
       " 'Term of Office: 25 July, 1992 to 25 July, 1997 ',\n",
       " 'Term of Office: 25 July, 1987 to 25 July, 1992 ',\n",
       " 'Term of Office: 25 July, 1982 to 25 July, 1987 ',\n",
       " 'Term of Office: 25 July, 1977 to 25 July, 1982 ',\n",
       " 'Term of Office: 24 August, 1974 to 11 February, 1977',\n",
       " 'Term of Office: 3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974',\n",
       " 'Term of Office: 13 May, 1967 to 3 May, 1969',\n",
       " 'Term of Office: 13 May, 1962 to 13 May, 1967',\n",
       " 'Term of Office: 26 January, 1950 to 13 May, 1962']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term = []\n",
    "for i in soup.find_all('div', class_=\"presidentListing\"):\n",
    "    term.append(i.text.split('\\n')[2])\n",
    "term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2c70ea9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind (birth - 1945)</td>\n",
       "      <td>Term of Office: 25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee (1935-2020)</td>\n",
       "      <td>Term of Office: 25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (birth - 1934)</td>\n",
       "      <td>Term of Office: 25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam (1931-2015)</td>\n",
       "      <td>Term of Office: 25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan (1920 - 2005)</td>\n",
       "      <td>Term of Office: 25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma (1918-1999)</td>\n",
       "      <td>Term of Office: 25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman (1910-2009)</td>\n",
       "      <td>Term of Office: 25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh (1916-1994)</td>\n",
       "      <td>Term of Office: 25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy (1913-1996)</td>\n",
       "      <td>Term of Office: 25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed (1905-1977)</td>\n",
       "      <td>Term of Office: 24 August, 1974 to 11 February...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri (1894-1980)</td>\n",
       "      <td>Term of Office: 3 May, 1969 to 20 July, 1969 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain (1897-1969)</td>\n",
       "      <td>Term of Office: 13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan (1888-1975)</td>\n",
       "      <td>Term of Office: 13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad (1884-1963)</td>\n",
       "      <td>Term of Office: 26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Name  \\\n",
       "0           Shri Ram Nath Kovind (birth - 1945)   \n",
       "1             Shri Pranab Mukherjee (1935-2020)   \n",
       "2   Smt Pratibha Devisingh Patil (birth - 1934)   \n",
       "3            DR. A.P.J. Abdul Kalam (1931-2015)   \n",
       "4            Shri K. R. Narayanan (1920 - 2005)   \n",
       "5           Dr Shankar Dayal Sharma (1918-1999)   \n",
       "6               Shri R Venkataraman (1910-2009)   \n",
       "7                  Giani Zail Singh (1916-1994)   \n",
       "8         Shri Neelam Sanjiva Reddy (1913-1996)   \n",
       "9          Dr. Fakhruddin Ali Ahmed (1905-1977)   \n",
       "10     Shri Varahagiri Venkata Giri (1894-1980)   \n",
       "11                 Dr. Zakir Husain (1897-1969)   \n",
       "12     Dr. Sarvepalli Radhakrishnan (1888-1975)   \n",
       "13             Dr. Rajendra Prasad (1884-1963)    \n",
       "\n",
       "                                       Term of Office  \n",
       "0     Term of Office: 25 July, 2017 to 25 July, 2022   \n",
       "1     Term of Office: 25 July, 2012 to 25 July, 2017   \n",
       "2     Term of Office: 25 July, 2007 to 25 July, 2012   \n",
       "3     Term of Office: 25 July, 2002 to 25 July, 2007   \n",
       "4     Term of Office: 25 July, 1997 to 25 July, 2002   \n",
       "5     Term of Office: 25 July, 1992 to 25 July, 1997   \n",
       "6     Term of Office: 25 July, 1987 to 25 July, 1992   \n",
       "7     Term of Office: 25 July, 1982 to 25 July, 1987   \n",
       "8     Term of Office: 25 July, 1977 to 25 July, 1982   \n",
       "9   Term of Office: 24 August, 1974 to 11 February...  \n",
       "10  Term of Office: 3 May, 1969 to 20 July, 1969 a...  \n",
       "11        Term of Office: 13 May, 1967 to 3 May, 1969  \n",
       "12       Term of Office: 13 May, 1962 to 13 May, 1967  \n",
       "13   Term of Office: 26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Name':names, 'Term of Office':term})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6eeca0",
   "metadata": {},
   "source": [
    "Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4354c79",
   "metadata": {},
   "source": [
    "Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1ccd225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1fe8d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India',\n",
       " 'Australia',\n",
       " 'New Zealand',\n",
       " 'England',\n",
       " 'Pakistan',\n",
       " 'South Africa',\n",
       " 'Bangladesh',\n",
       " 'Sri Lanka',\n",
       " 'Afghanistan',\n",
       " 'West Indies',\n",
       " 'Ireland',\n",
       " 'Scotland',\n",
       " 'Zimbabwe',\n",
       " 'Namibia',\n",
       " 'Netherlands',\n",
       " 'Oman',\n",
       " 'UAE',\n",
       " 'United States',\n",
       " 'Nepal',\n",
       " 'Papua New Guinea']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team = []\n",
    "first_team = soup.find('span', class_=\"u-hide-phablet\")\n",
    "team.append(first_team.text)\n",
    "\n",
    "for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "    team.append(i.text.split('\\n')[4])\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f079e6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['44',\n",
       " '32',\n",
       " '29',\n",
       " '33',\n",
       " '25',\n",
       " '27',\n",
       " '33',\n",
       " '34',\n",
       " '20',\n",
       " '41',\n",
       " '25',\n",
       " '31',\n",
       " '28',\n",
       " '27',\n",
       " '21',\n",
       " '30',\n",
       " '25',\n",
       " '31',\n",
       " '29',\n",
       " '30']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = []\n",
    "first_match = soup.find('td', class_=\"rankings-block__banner--matches\")\n",
    "matches.append(first_match.text)\n",
    "\n",
    "for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "    matches.append(i.text.split('\\n')[7])\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc7c420f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,010',\n",
       " '3,572',\n",
       " '3,229',\n",
       " '3,656',\n",
       " '2,649',\n",
       " '2,775',\n",
       " '3,129',\n",
       " '2,976',\n",
       " '1,419',\n",
       " '2,902',\n",
       " '1,300',\n",
       " '1,459',\n",
       " '1,201',\n",
       " '937',\n",
       " '673',\n",
       " '919',\n",
       " '693',\n",
       " '821',\n",
       " '543',\n",
       " '128']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = []\n",
    "first_point = soup.find('td', class_=\"rankings-block__banner--points\")\n",
    "points.append(first_point.text)\n",
    "for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "    points.append(i.text.split('\\n')[8])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6dda275c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                            114',\n",
       " '112',\n",
       " '111',\n",
       " '111',\n",
       " '106',\n",
       " '103',\n",
       " '95',\n",
       " '88',\n",
       " '71',\n",
       " '71',\n",
       " '52',\n",
       " '47',\n",
       " '43',\n",
       " '35',\n",
       " '32',\n",
       " '31',\n",
       " '28',\n",
       " '26',\n",
       " '19',\n",
       " '4']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = []\n",
    "first_rating = soup.find('td', class_=\"rankings-block__banner--rating u-text-right\")\n",
    "rating.append(first_rating.text.split('\\n')[1])\n",
    "for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "    rating.append(i.text.split('\\n')[9])\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ae944f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>44</td>\n",
       "      <td>5,010</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>32</td>\n",
       "      <td>3,572</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>29</td>\n",
       "      <td>3,229</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>33</td>\n",
       "      <td>3,656</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>25</td>\n",
       "      <td>2,649</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>27</td>\n",
       "      <td>2,775</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>33</td>\n",
       "      <td>3,129</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>34</td>\n",
       "      <td>2,976</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>20</td>\n",
       "      <td>1,419</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Team Matches Points                          Ratings\n",
       "0         India      44  5,010                              114\n",
       "1     Australia      32  3,572                              112\n",
       "2   New Zealand      29  3,229                              111\n",
       "3       England      33  3,656                              111\n",
       "4      Pakistan      25  2,649                              106\n",
       "5  South Africa      27  2,775                              103\n",
       "6    Bangladesh      33  3,129                               95\n",
       "7     Sri Lanka      34  2,976                               88\n",
       "8   Afghanistan      20  1,419                               71\n",
       "9   West Indies      41  2,902                               71"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Team':team, 'Matches':matches, 'Points': points, 'Ratings':rating})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf3bb62",
   "metadata": {},
   "source": [
    "Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95434b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3fe8819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babar Azam',\n",
       " 'Rassie van der Dussen',\n",
       " 'David Warner',\n",
       " 'Quinton de Kock',\n",
       " 'Imam-ul-Haq',\n",
       " 'Shubman Gill',\n",
       " 'Virat Kohli',\n",
       " 'Steve Smith',\n",
       " 'Rohit Sharma',\n",
       " 'Kane Williamson']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player = []\n",
    "first_player = soup.find('div', class_=\"rankings-block__banner--name-large\")\n",
    "player.append(first_player.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player.append(i.text.split('\\n')[1])\n",
    "player[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48b090e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAK', 'SA', 'AUS', 'SA', 'PAK', 'IND', 'IND', 'AUS', 'IND', 'NZ']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team= []\n",
    "first_team = soup.find('div', class_=\"rankings-block__banner--nationality\")\n",
    "team.append(first_team.text.split('\\n')[2])\n",
    "\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text)\n",
    "team[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b14d65f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['887', '787', '747', '743', '740', '734', '727', '719', '719', '700']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate2= []\n",
    "first_rate2 = soup.find('div', class_=\"rankings-block__banner--rating\")\n",
    "rate2.append(first_rate2.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rate2.append(i.text)\n",
    "rate2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae67cf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAK</td>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SA</td>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUS</td>\n",
       "      <td>David Warner</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SA</td>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAK</td>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IND</td>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IND</td>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IND</td>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NZ</td>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team                 Player Ratings\n",
       "0  PAK             Babar Azam     887\n",
       "1   SA  Rassie van der Dussen     787\n",
       "2  AUS           David Warner     747\n",
       "3   SA        Quinton de Kock     743\n",
       "4  PAK            Imam-ul-Haq     740\n",
       "5  IND           Shubman Gill     734\n",
       "6  IND            Virat Kohli     727\n",
       "7  AUS            Steve Smith     719\n",
       "8  IND           Rohit Sharma     719\n",
       "9   NZ        Kane Williamson     700"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Team':team, 'Player':player, 'Ratings':rate2})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc92eb",
   "metadata": {},
   "source": [
    "Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "15758c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d79f9944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mohammed Siraj',\n",
       " 'Josh Hazlewood',\n",
       " 'Trent Boult',\n",
       " 'Mitchell Starc',\n",
       " 'Rashid Khan',\n",
       " 'Adam Zampa',\n",
       " 'Shakib Al Hasan',\n",
       " 'Shaheen Afridi',\n",
       " 'Mustafizur Rahman',\n",
       " 'Mujeeb Ur Rahman']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player = []\n",
    "first_player = soup.find('div', class_=\"rankings-block__banner--name-large\")\n",
    "player.append(first_player.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player.append(i.text.split('\\n')[1])\n",
    "player[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a0447ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IND', 'AUS', 'NZ', 'AUS', 'AFG', 'AUS', 'BAN', 'PAK', 'BAN', 'AFG']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team= []\n",
    "first_team = soup.find('div', class_=\"rankings-block__banner--nationality\")\n",
    "team.append(first_team.text.split('\\n')[2])\n",
    "\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text)\n",
    "team[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ea3d736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['729', '727', '708', '665', '659', '655', '652', '641', '638', '637']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate2= []\n",
    "first_rate2 = soup.find('div', class_=\"rankings-block__banner--rating\")\n",
    "rate2.append(first_rate2.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rate2.append(i.text)\n",
    "rate2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "708d6931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IND</td>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NZ</td>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BAN</td>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PAK</td>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BAN</td>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team             Player Ratings\n",
       "0  IND     Mohammed Siraj     729\n",
       "1  AUS     Josh Hazlewood     727\n",
       "2   NZ        Trent Boult     708\n",
       "3  AUS     Mitchell Starc     665\n",
       "4  AFG        Rashid Khan     659\n",
       "5  AUS         Adam Zampa     655\n",
       "6  BAN    Shakib Al Hasan     652\n",
       "7  PAK     Shaheen Afridi     641\n",
       "8  BAN  Mustafizur Rahman     638\n",
       "9  AFG   Mujeeb Ur Rahman     637"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Team':team, 'Player':player, 'Ratings':rate2})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e68c7d",
   "metadata": {},
   "source": [
    "Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df85f3a",
   "metadata": {},
   "source": [
    "Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6969b53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7fc2740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australia',\n",
       " 'England',\n",
       " 'South Africa',\n",
       " 'India',\n",
       " 'New Zealand',\n",
       " 'West Indies',\n",
       " 'Bangladesh',\n",
       " 'Thailand',\n",
       " 'Pakistan',\n",
       " 'Sri Lanka',\n",
       " 'Ireland',\n",
       " 'Netherlands',\n",
       " 'Zimbabwe']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team = []\n",
    "first_team = soup.find('span', class_=\"u-hide-phablet\")\n",
    "team.append(first_team.text)\n",
    "\n",
    "for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "    team.append(i.text.split('\\n')[4])\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28f03e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21', '28', '26', '27', '25', '27', '13', '8', '27', '8', '14', '9', '8']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = []\n",
    "first_match = soup.find('td', class_=\"rankings-block__banner--matches\")\n",
    "matches.append(first_match.text)\n",
    "\n",
    "for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "    matches.append(i.text.split('\\n')[7])\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc570c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3,603',\n",
       " '3,342',\n",
       " '3,098',\n",
       " '2,820',\n",
       " '2,553',\n",
       " '2,535',\n",
       " '983',\n",
       " '572',\n",
       " '1,678',\n",
       " '353',\n",
       " '548',\n",
       " '0',\n",
       " '0']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = []\n",
    "first_point = soup.find('td', class_=\"rankings-block__banner--points\")\n",
    "points.append(first_point.text)\n",
    "for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "    points.append(i.text.split('\\n')[8])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b75e67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                            172',\n",
       " '119',\n",
       " '119',\n",
       " '104',\n",
       " '102',\n",
       " '94',\n",
       " '76',\n",
       " '72',\n",
       " '62',\n",
       " '44',\n",
       " '39',\n",
       " '0',\n",
       " '0']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = []\n",
    "first_rating = soup.find('td', class_=\"rankings-block__banner--rating u-text-right\")\n",
    "rating.append(first_rating.text.split('\\n')[1])\n",
    "for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "    rating.append(i.text.split('\\n')[9])\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6e668dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>21</td>\n",
       "      <td>3,603</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>28</td>\n",
       "      <td>3,342</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>25</td>\n",
       "      <td>2,553</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>2,535</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>13</td>\n",
       "      <td>983</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>8</td>\n",
       "      <td>572</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>1,678</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>8</td>\n",
       "      <td>353</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Team Matches Points                          Ratings\n",
       "0     Australia      21  3,603                              172\n",
       "1       England      28  3,342                              119\n",
       "2  South Africa      26  3,098                              119\n",
       "3         India      27  2,820                              104\n",
       "4   New Zealand      25  2,553                              102\n",
       "5   West Indies      27  2,535                               94\n",
       "6    Bangladesh      13    983                               76\n",
       "7      Thailand       8    572                               72\n",
       "8      Pakistan      27  1,678                               62\n",
       "9     Sri Lanka       8    353                               44"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Team':team, 'Matches':matches, 'Points': points, 'Ratings':rating})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7badf9f5",
   "metadata": {},
   "source": [
    "Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dded901e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1526ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alyssa Healy',\n",
       " 'Beth Mooney',\n",
       " 'Laura Wolvaardt',\n",
       " 'Natalie Sciver',\n",
       " 'Meg Lanning',\n",
       " 'Harmanpreet Kaur',\n",
       " 'Smriti Mandhana',\n",
       " 'Rachael Haynes',\n",
       " 'Chamari Athapaththu',\n",
       " 'Amy Satterthwaite']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player = []\n",
    "first_player = soup.find('div', class_=\"rankings-block__banner--name-large\")\n",
    "player.append(first_player.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player.append(i.text.split('\\n')[1])\n",
    "player[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4882c76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUS', 'AUS', 'SA', 'ENG', 'AUS', 'IND', 'IND', 'AUS', 'SL', 'NZ']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team= []\n",
    "first_team = soup.find('div', class_=\"rankings-block__banner--nationality\")\n",
    "team.append(first_team.text.split('\\n')[2])\n",
    "\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text)\n",
    "team[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe05220d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['762', '754', '732', '731', '717', '716', '714', '680', '655', '641']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate2= []\n",
    "first_rate2 = soup.find('div', class_=\"rankings-block__banner--rating\")\n",
    "rate2.append(first_rate2.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rate2.append(i.text)\n",
    "rate2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1655da9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SA</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENG</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IND</td>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IND</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SL</td>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NZ</td>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team               Player Ratings\n",
       "0  AUS         Alyssa Healy     762\n",
       "1  AUS          Beth Mooney     754\n",
       "2   SA      Laura Wolvaardt     732\n",
       "3  ENG       Natalie Sciver     731\n",
       "4  AUS          Meg Lanning     717\n",
       "5  IND     Harmanpreet Kaur     716\n",
       "6  IND      Smriti Mandhana     714\n",
       "7  AUS       Rachael Haynes     680\n",
       "8   SL  Chamari Athapaththu     655\n",
       "9   NZ    Amy Satterthwaite     641"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Team':team, 'Player':player, 'Ratings':rate2})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206cc44",
   "metadata": {},
   "source": [
    "Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c350cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "290fc931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hayley Matthews',\n",
       " 'Natalie Sciver',\n",
       " 'Ellyse Perry',\n",
       " 'Marizanne Kapp',\n",
       " 'Amelia Kerr',\n",
       " 'Deepti Sharma',\n",
       " 'Ashleigh Gardner',\n",
       " 'Jess Jonassen',\n",
       " 'Nida Dar',\n",
       " 'Jhulan Goswami']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player = []\n",
    "first_player = soup.find('div', class_=\"rankings-block__banner--name-large\")\n",
    "player.append(first_player.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player.append(i.text.split('\\n')[1])\n",
    "player[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f2391451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WI', 'ENG', 'AUS', 'SA', 'NZ', 'IND', 'AUS', 'AUS', 'PAK', 'IND']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team= []\n",
    "first_team = soup.find('div', class_=\"rankings-block__banner--nationality\")\n",
    "team.append(first_team.text.split('\\n')[2])\n",
    "\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text)\n",
    "team[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a93c5f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['373', '371', '366', '349', '336', '322', '292', '250', '232', '214']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate2= []\n",
    "first_rate2 = soup.find('div', class_=\"rankings-block__banner--rating\")\n",
    "rate2.append(first_rate2.text)\n",
    "\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rate2.append(i.text)\n",
    "rate2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bdabfe58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WI</td>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENG</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SA</td>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NZ</td>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IND</td>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUS</td>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PAK</td>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IND</td>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team            Player Ratings\n",
       "0   WI   Hayley Matthews     373\n",
       "1  ENG    Natalie Sciver     371\n",
       "2  AUS      Ellyse Perry     366\n",
       "3   SA    Marizanne Kapp     349\n",
       "4   NZ       Amelia Kerr     336\n",
       "5  IND     Deepti Sharma     322\n",
       "6  AUS  Ashleigh Gardner     292\n",
       "7  AUS     Jess Jonassen     250\n",
       "8  PAK          Nida Dar     232\n",
       "9  IND    Jhulan Goswami     214"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Team':team, 'Player':player, 'Ratings':rate2})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba101275",
   "metadata": {},
   "source": [
    "Question  7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "093529c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c19ff1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12 Min Ago',\n",
       " '37 Min Ago',\n",
       " '45 Min Ago',\n",
       " '47 Min Ago',\n",
       " '1 Hour Ago',\n",
       " '1 Hour Ago',\n",
       " '2 Hours Ago',\n",
       " '2 Hours Ago',\n",
       " '2 Hours Ago',\n",
       " '2 Hours Ago',\n",
       " '3 Hours Ago',\n",
       " '3 Hours Ago',\n",
       " '3 Hours Ago',\n",
       " '3 Hours Ago',\n",
       " '4 Hours Ago',\n",
       " '4 Hours Ago',\n",
       " '4 Hours Ago',\n",
       " '4 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '5 Hours Ago',\n",
       " '6 Hours Ago']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = []\n",
    "for i in soup.find_all('time',class_=\"LatestNews-timestamp\"):\n",
    "    time.append(i.text)\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "08b4ab7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The best fixed income deals for investors as interest rates surge higher',\n",
       " 'Rocket Lab quarterly revenue stays steady as space company doubles order backlog',\n",
       " 'Norwegian Cruise Line shares fall 10% after company issues soft outlook',\n",
       " 'FDA advisors recommend Pfizer RSV vaccine for older adults despite risks',\n",
       " 'Rivian posts mixed fourth quarter and underwhelming EV production outlook',\n",
       " 'Virgin Galactic completes lengthy upgrade process ahead of resuming spaceflights',\n",
       " 'Bitcoin, ether on track for a positive February despite fading 2023 risk rally',\n",
       " \"As sales slow, Target leans into 'affordable joy' and its cheap chic reputation\",\n",
       " \"How watching videos of police brutality impact Black People's mental health\",\n",
       " 'These stocks won February — but it may be time to dump 2 popular tech plays',\n",
       " \"High home prices, rising mortgage rates: It's tough being a first-time homebuyer\",\n",
       " 'Biden taps CEOs of 3M, CVS, FedEx, Citi, others to join Export Council on trade',\n",
       " 'Washington state is holding its first carbon allowance auction',\n",
       " 'These are the most popular ETFs among investors heading into March',\n",
       " \"We're adding to our position in this robust medical technology player\",\n",
       " 'This biotech startup has a chance to grab a piece of the obesity drug market',\n",
       " 'What to know as student debt forgiveness heads to the Supreme Court',\n",
       " 'Biden warns of GOP plans to curb access to health care ',\n",
       " 'Black real estate developers get access to big capital through Philadelphia program',\n",
       " 'Stocks making the biggest moves midday: Norwegian Cruise Line, Target & more',\n",
       " \"Corporate CFOs are going through their own 'Great Resignation'\",\n",
       " \"These 'fortress' stocks are beating market this year as a perilous March looms\",\n",
       " \"DeSantis calls for 'crippling the ESG movement' in new book\",\n",
       " 'UAW leadership faces historic upheaval ahead of automakers negotiations',\n",
       " \"'Ant-Man and the Wasp: Quantumania' box office had steep decline in second week\",\n",
       " 'FTX ex-engineering chief Nishad Singh pleads guilty to criminal charges',\n",
       " '3 investing lessons from the Club’s meeting Tuesday',\n",
       " \"Bank of America says A.I. 'is the new electricity,’ names its top picks\",\n",
       " 'Annual Meeting update on 10 tech stocks, plus Disney, in the Club portfolio',\n",
       " 'Bond yields are close to a major psychological level that could spook stocks']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = []\n",
    "for i in soup.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    news.append(i.text)\n",
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "118471ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.cnbc.com/2023/02/28/the-best-fixed-income-deals-for-investors-as-interest-rates-surge-higher.html',\n",
       " 'https://www.cnbc.com/2023/02/28/rocket-lab-rklb-q4-2022-earnings.html',\n",
       " 'https://www.cnbc.com/2023/02/28/norwegian-cruise-line-shares-fall-earnings.html',\n",
       " 'https://www.cnbc.com/2023/02/28/rsv-vaccine-fda-committee-votes-on-pfizer-shot-for-older-adults.html',\n",
       " 'https://www.cnbc.com/2023/02/28/rivian-rivn-earnings-q4-2022.html',\n",
       " 'https://www.cnbc.com/2023/02/28/virgin-galactic-spce-q4-2022-earnings.html',\n",
       " 'https://www.cnbc.com/2023/02/28/bitcoin-ether-on-track-for-a-positive-february-despite-fading-2023-risk-rally.html',\n",
       " 'https://www.cnbc.com/2023/02/28/target-affordable-joy-cheap-chic-sales-slow.html',\n",
       " 'https://www.cnbc.com/2023/02/28/how-videos-of-police-brutality-can-harm-black-peoples-mental-health.html',\n",
       " 'https://www.cnbc.com/2023/02/28/these-stocks-won-february-but-it-may-be-time-to-dump-2-popular-tech-plays.html',\n",
       " 'https://www.cnbc.com/2023/02/28/home-prices-mortgage-rates-its-tough-being-a-first-time-homebuyer.html',\n",
       " 'https://www.cnbc.com/2023/02/28/biden-taps-ceos-of-3m-cvs-fedex-citi-others-to-join-his-export-council-on-trade.html',\n",
       " 'https://www.cnbc.com/2023/02/28/washington-state-is-holding-its-first-carbon-allowance-auction.html',\n",
       " 'https://www.cnbc.com/2023/02/28/these-are-the-most-popular-etfs-among-investors-heading-into-march.html',\n",
       " 'https://www.cnbc.com/2023/02/28/were-adding-to-our-position-in-this-robust-medical-technology-player.html',\n",
       " 'https://www.cnbc.com/2023/02/28/this-startup-can-grab-a-piece-of-the-lucrative-obesity-drug-market.html',\n",
       " 'https://www.cnbc.com/2023/02/28/student-debt-forgiveness-heads-to-the-supreme-courtwhat-to-know.html',\n",
       " 'https://www.cnbc.com/2023/02/28/watch-live-biden-warns-of-gop-plans-to-curb-health-care-in-virginia.html',\n",
       " 'https://www.cnbc.com/2023/02/28/black-real-estate-developers-access-capital.html',\n",
       " 'https://www.cnbc.com/2023/02/28/stocks-making-the-biggest-moves-midday-nclh-tgt-aap.html',\n",
       " 'https://www.cnbc.com/2023/02/28/corporate-cfos-are-going-through-their-own-great-resignation.html',\n",
       " 'https://www.cnbc.com/2023/02/28/fortress-stocks-beating-the-market-this-year-for-a-perilous-march.html',\n",
       " 'https://www.cnbc.com/2023/02/28/ron-desantis-calls-for-crippling-the-esg-movement-in-new-book.html',\n",
       " 'https://www.cnbc.com/2023/02/28/uaw-presidential-runoff.html',\n",
       " 'https://www.cnbc.com/2023/02/28/ant-man-and-the-wasp-quantumania-box-office.html',\n",
       " 'https://www.cnbc.com/2023/02/28/ftx-ex-engineering-head-nishad-singh-pleads-guilty-to-criminal-charges.html',\n",
       " 'https://www.cnbc.com/2023/02/28/jim-cramers-investing-club-meeting-tuesday-oil-meta-linde.html',\n",
       " 'https://www.cnbc.com/2023/02/28/bank-of-america-says-ai-is-the-new-electricity-names-its-top-picks-to-play-the-breakout-trend.html',\n",
       " 'https://www.cnbc.com/2023/02/28/heres-our-annual-meeting-update-on-10-tech-stocks-plus-disney-in-the-club-portfolio.html',\n",
       " 'https://www.cnbc.com/2023/02/28/bond-yields-are-close-to-a-major-psychological-level-that-could-really-spook-the-stock-market.html']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = []\n",
    "for i in soup.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    link.append(i.get('href'))\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc6fc747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The best fixed income deals for investors as i...</td>\n",
       "      <td>12 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/the-best-fixed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rocket Lab quarterly revenue stays steady as s...</td>\n",
       "      <td>37 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/rocket-lab-rkl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norwegian Cruise Line shares fall 10% after co...</td>\n",
       "      <td>45 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/norwegian-crui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDA advisors recommend Pfizer RSV vaccine for ...</td>\n",
       "      <td>47 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/rsv-vaccine-fd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rivian posts mixed fourth quarter and underwhe...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/rivian-rivn-ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Virgin Galactic completes lengthy upgrade proc...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/virgin-galacti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bitcoin, ether on track for a positive Februar...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/bitcoin-ether-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>As sales slow, Target leans into 'affordable j...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/target-afforda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How watching videos of police brutality impact...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/how-videos-of-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>These stocks won February — but it may be time...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/these-stocks-w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>High home prices, rising mortgage rates: It's ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/home-prices-mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Biden taps CEOs of 3M, CVS, FedEx, Citi, other...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/biden-taps-ceo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Washington state is holding its first carbon a...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/washington-sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>These are the most popular ETFs among investor...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/these-are-the-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>We're adding to our position in this robust me...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/were-adding-to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>This biotech startup has a chance to grab a pi...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/this-startup-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What to know as student debt forgiveness heads...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/student-debt-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Biden warns of GOP plans to curb access to hea...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/watch-live-bid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Black real estate developers get access to big...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/black-real-est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Stocks making the biggest moves midday: Norweg...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/stocks-making-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Corporate CFOs are going through their own 'Gr...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/corporate-cfos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>These 'fortress' stocks are beating market thi...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/fortress-stock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DeSantis calls for 'crippling the ESG movement...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/ron-desantis-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>UAW leadership faces historic upheaval ahead o...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/uaw-presidenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'Ant-Man and the Wasp: Quantumania' box office...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/ant-man-and-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>FTX ex-engineering chief Nishad Singh pleads g...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/ftx-ex-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3 investing lessons from the Club’s meeting Tu...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/jim-cramers-in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Bank of America says A.I. 'is the new electric...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/bank-of-americ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Annual Meeting update on 10 tech stocks, plus ...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/heres-our-annu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bond yields are close to a major psychological...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/02/28/bond-yields-ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline         Time  \\\n",
       "0   The best fixed income deals for investors as i...   12 Min Ago   \n",
       "1   Rocket Lab quarterly revenue stays steady as s...   37 Min Ago   \n",
       "2   Norwegian Cruise Line shares fall 10% after co...   45 Min Ago   \n",
       "3   FDA advisors recommend Pfizer RSV vaccine for ...   47 Min Ago   \n",
       "4   Rivian posts mixed fourth quarter and underwhe...   1 Hour Ago   \n",
       "5   Virgin Galactic completes lengthy upgrade proc...   1 Hour Ago   \n",
       "6   Bitcoin, ether on track for a positive Februar...  2 Hours Ago   \n",
       "7   As sales slow, Target leans into 'affordable j...  2 Hours Ago   \n",
       "8   How watching videos of police brutality impact...  2 Hours Ago   \n",
       "9   These stocks won February — but it may be time...  2 Hours Ago   \n",
       "10  High home prices, rising mortgage rates: It's ...  3 Hours Ago   \n",
       "11  Biden taps CEOs of 3M, CVS, FedEx, Citi, other...  3 Hours Ago   \n",
       "12  Washington state is holding its first carbon a...  3 Hours Ago   \n",
       "13  These are the most popular ETFs among investor...  3 Hours Ago   \n",
       "14  We're adding to our position in this robust me...  4 Hours Ago   \n",
       "15  This biotech startup has a chance to grab a pi...  4 Hours Ago   \n",
       "16  What to know as student debt forgiveness heads...  4 Hours Ago   \n",
       "17  Biden warns of GOP plans to curb access to hea...  4 Hours Ago   \n",
       "18  Black real estate developers get access to big...  5 Hours Ago   \n",
       "19  Stocks making the biggest moves midday: Norweg...  5 Hours Ago   \n",
       "20  Corporate CFOs are going through their own 'Gr...  5 Hours Ago   \n",
       "21  These 'fortress' stocks are beating market thi...  5 Hours Ago   \n",
       "22  DeSantis calls for 'crippling the ESG movement...  5 Hours Ago   \n",
       "23  UAW leadership faces historic upheaval ahead o...  5 Hours Ago   \n",
       "24  'Ant-Man and the Wasp: Quantumania' box office...  5 Hours Ago   \n",
       "25  FTX ex-engineering chief Nishad Singh pleads g...  5 Hours Ago   \n",
       "26  3 investing lessons from the Club’s meeting Tu...  5 Hours Ago   \n",
       "27  Bank of America says A.I. 'is the new electric...  5 Hours Ago   \n",
       "28  Annual Meeting update on 10 tech stocks, plus ...  5 Hours Ago   \n",
       "29  Bond yields are close to a major psychological...  6 Hours Ago   \n",
       "\n",
       "                                                Links  \n",
       "0   https://www.cnbc.com/2023/02/28/the-best-fixed...  \n",
       "1   https://www.cnbc.com/2023/02/28/rocket-lab-rkl...  \n",
       "2   https://www.cnbc.com/2023/02/28/norwegian-crui...  \n",
       "3   https://www.cnbc.com/2023/02/28/rsv-vaccine-fd...  \n",
       "4   https://www.cnbc.com/2023/02/28/rivian-rivn-ea...  \n",
       "5   https://www.cnbc.com/2023/02/28/virgin-galacti...  \n",
       "6   https://www.cnbc.com/2023/02/28/bitcoin-ether-...  \n",
       "7   https://www.cnbc.com/2023/02/28/target-afforda...  \n",
       "8   https://www.cnbc.com/2023/02/28/how-videos-of-...  \n",
       "9   https://www.cnbc.com/2023/02/28/these-stocks-w...  \n",
       "10  https://www.cnbc.com/2023/02/28/home-prices-mo...  \n",
       "11  https://www.cnbc.com/2023/02/28/biden-taps-ceo...  \n",
       "12  https://www.cnbc.com/2023/02/28/washington-sta...  \n",
       "13  https://www.cnbc.com/2023/02/28/these-are-the-...  \n",
       "14  https://www.cnbc.com/2023/02/28/were-adding-to...  \n",
       "15  https://www.cnbc.com/2023/02/28/this-startup-c...  \n",
       "16  https://www.cnbc.com/2023/02/28/student-debt-f...  \n",
       "17  https://www.cnbc.com/2023/02/28/watch-live-bid...  \n",
       "18  https://www.cnbc.com/2023/02/28/black-real-est...  \n",
       "19  https://www.cnbc.com/2023/02/28/stocks-making-...  \n",
       "20  https://www.cnbc.com/2023/02/28/corporate-cfos...  \n",
       "21  https://www.cnbc.com/2023/02/28/fortress-stock...  \n",
       "22  https://www.cnbc.com/2023/02/28/ron-desantis-c...  \n",
       "23  https://www.cnbc.com/2023/02/28/uaw-presidenti...  \n",
       "24  https://www.cnbc.com/2023/02/28/ant-man-and-th...  \n",
       "25  https://www.cnbc.com/2023/02/28/ftx-ex-enginee...  \n",
       "26  https://www.cnbc.com/2023/02/28/jim-cramers-in...  \n",
       "27  https://www.cnbc.com/2023/02/28/bank-of-americ...  \n",
       "28  https://www.cnbc.com/2023/02/28/heres-our-annu...  \n",
       "29  https://www.cnbc.com/2023/02/28/bond-yields-ar...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Headline':news, 'Time':time, 'Links': link})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b9231",
   "metadata": {},
   "source": [
    "Question 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4b3ee87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1404f5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reward is enough',\n",
       " 'Making sense of raw input',\n",
       " 'Law and logic: A review from an argumentation perspective',\n",
       " 'Creativity and artificial intelligence',\n",
       " 'Artificial cognition for social human–robot interaction: An implementation',\n",
       " 'Explanation in artificial intelligence: Insights from the social sciences',\n",
       " 'Making sense of sensory input',\n",
       " 'Conflict-based search for optimal multi-agent pathfinding',\n",
       " 'Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning',\n",
       " 'The Hanabi challenge: A new frontier for AI research',\n",
       " 'Evaluating XAI: A comparison of rule-based and example-based explanations',\n",
       " 'Argumentation in artificial intelligence',\n",
       " 'Algorithms for computing strategies in two-player simultaneous move games',\n",
       " 'Multiple object tracking: A literature review',\n",
       " 'Selection of relevant features and examples in machine learning',\n",
       " 'A survey of inverse reinforcement learning: Challenges, methods and progress',\n",
       " 'Explaining individual predictions when features are dependent: More accurate approximations to Shapley values',\n",
       " 'A review of possible effects of cognitive biases on interpretation of rule-based machine learning models',\n",
       " 'Integrating social power into the decision-making of cognitive agents',\n",
       " \"“That's (not) the output I expected!” On the role of end user expectations in creating explanations of AI systems\",\n",
       " 'Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies',\n",
       " 'Algorithm runtime prediction: Methods & evaluation',\n",
       " 'Wrappers for feature subset selection',\n",
       " 'Commonsense visual sensemaking for autonomous driving – On generalised neurosymbolic online abduction integrating vision and semantics',\n",
       " 'Quantum computation, quantum theory and AI']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = []\n",
    "for i in soup.find_all('h2',class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"):\n",
    "    title.append(i.text)\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ddca10b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Silver, David, Singh, Satinder, Precup, Doina, Sutton, Richard S. ',\n",
       " 'Evans, Richard, Bošnjak, Matko and 5 more',\n",
       " 'Prakken, Henry, Sartor, Giovanni ',\n",
       " 'Boden, Margaret A. ',\n",
       " 'Lemaignan, Séverin, Warnier, Mathieu and 3 more',\n",
       " 'Miller, Tim ',\n",
       " 'Evans, Richard, Hernández-Orallo, José and 3 more',\n",
       " 'Sharon, Guni, Stern, Roni, Felner, Ariel, Sturtevant, Nathan R. ',\n",
       " 'Sutton, Richard S., Precup, Doina, Singh, Satinder ',\n",
       " 'Bard, Nolan, Foerster, Jakob N. and 13 more',\n",
       " 'van der Waa, Jasper, Nieuwburg, Elisabeth, Cremers, Anita, Neerincx, Mark ',\n",
       " 'Bench-Capon, T.J.M., Dunne, Paul E. ',\n",
       " 'Bošanský, Branislav, Lisý, Viliam and 3 more',\n",
       " 'Luo, Wenhan, Xing, Junliang and 4 more',\n",
       " 'Blum, Avrim L., Langley, Pat ',\n",
       " 'Arora, Saurabh, Doshi, Prashant ',\n",
       " 'Aas, Kjersti, Jullum, Martin, Løland, Anders ',\n",
       " 'Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Johannes ',\n",
       " 'Pereira, Gonçalo, Prada, Rui, Santos, Pedro A. ',\n",
       " 'Riveiro, Maria, Thill, Serge ',\n",
       " 'Kenny, Eoin M., Ford, Courtney, Quinn, Molly, Keane, Mark T. ',\n",
       " 'Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyton-Brown, Kevin ',\n",
       " 'Kohavi, Ron, John, George H. ',\n",
       " 'Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srikrishna ',\n",
       " 'Ying, Mingsheng ']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = []\n",
    "for i in soup.find_all('span',class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    author.append(i.text)\n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "13b37ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['October 2021',\n",
       " 'October 2021',\n",
       " 'October 2015',\n",
       " 'August 1998',\n",
       " 'June 2017',\n",
       " 'February 2019',\n",
       " 'April 2021',\n",
       " 'February 2015',\n",
       " 'August 1999',\n",
       " 'March 2020',\n",
       " 'February 2021',\n",
       " 'October 2007',\n",
       " 'August 2016',\n",
       " 'April 2021',\n",
       " 'December 1997',\n",
       " 'August 2021',\n",
       " 'September 2021',\n",
       " 'June 2021',\n",
       " 'December 2016',\n",
       " 'September 2021',\n",
       " 'May 2021',\n",
       " 'January 2014',\n",
       " 'December 1997',\n",
       " 'October 2021',\n",
       " 'February 2010']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = []\n",
    "for i in soup.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    date.append(i.text)\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3dfcda3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.sciencedirect.com/science/article/pii/S0004370221000862',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000722',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370215000910',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370298000551',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300790',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370218305988',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301855',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370214001386',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370299000521',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370219300116',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301533',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370207000793',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300285',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370220301958',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370297000635',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000515',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000539',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000096',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370216300868',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000588',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000102',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370213001082',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S000437029700043X',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370221000734',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0004370209001398']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = []\n",
    "for i in soup.find_all('a',class_=\"sc-5smygv-0 fIXTHm\"):\n",
    "    links.append(i.get('href'))\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "065f5ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                               Author  Published Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper Url  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Paper Title':title, 'Author':author ,'Published Date':date, 'Paper Url': links})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec6aad9",
   "metadata": {},
   "source": [
    "Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "208a64ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cb74b995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Castle Barbeque',\n",
       " 'Jungle Jamboree',\n",
       " 'Cafe Knosh',\n",
       " 'Castle Barbeque',\n",
       " 'The Barbeque Company',\n",
       " 'India Grill',\n",
       " 'Delhi Barbeque',\n",
       " 'The Monarch - Bar Be Que Village',\n",
       " 'Indian Grill Room']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rname = []\n",
    "for i in soup.find_all('a',class_=\"restnt-name ellipsis\"):\n",
    "    rname.append(i.text)\n",
    "rname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "87f37284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Connaught Place, Central Delhi',\n",
       " '3CS Mall,Lajpat Nagar - 3, South Delhi',\n",
       " 'The Leela Ambience Convention Hotel,Shahdara, East Delhi',\n",
       " 'Pacific Mall,Tagore Garden, West Delhi',\n",
       " 'Gardens Galleria,Sector 38A, Noida',\n",
       " 'Hilton Garden Inn,Saket, South Delhi',\n",
       " 'Taurus Sarovar Portico,Mahipalpur, South Delhi',\n",
       " 'Indirapuram Habitat Centre,Indirapuram, Ghaziabad',\n",
       " 'Suncity Business Tower,Golf Course Road, Gurgaon']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc = []\n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    loc.append(i.text)\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6b016c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/k/b/p86792-16062953735fbe1f4d3fb7e.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/p/m/p59633-166088382462ff137009010.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/4/p/m/p406-15438184745c04ccea491bc.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/j/o/p38113-15959192065f1fcb666130c.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/7/p/k/p79307-16051787755fad1597f2bf9.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/2/v/t/p2687-1482477169585cce712b90f.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/d/i/p52501-1661855212630de5eceb6d2.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/3/n/o/p34822-15599107305cfa594a13c24.jpg?tr=tr:n-medium',\n",
       " 'https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/y/f/p549-165000147262590640c0afc.jpg?tr=tr:n-medium']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = []\n",
    "for i in soup.find_all('img',class_=\"no-img\"):\n",
    "    img.append(i.get('data-src'))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1233d16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 2,000 for 2 (approx) ',\n",
       " '₹ 1,680 for 2 (approx) ',\n",
       " '₹ 3,000 for 2 (approx) ',\n",
       " '₹ 2,000 for 2 (approx) ',\n",
       " '₹ 1,700 for 2 (approx) ',\n",
       " '₹ 2,400 for 2 (approx) ',\n",
       " '₹ 1,800 for 2 (approx) ',\n",
       " '₹ 1,900 for 2 (approx) ',\n",
       " '₹ 2,200 for 2 (approx) ']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = []\n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    price.append(i.text.split('|')[0])\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb2f70f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.1', '3.9', '4.3', '3.9', '3.9', '3.9', '3.6', '3.8', '4.3']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating1 = []\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    rating1.append(i.text)\n",
    "rating1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "93dde7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Chinese, North Indian',\n",
       " ' North Indian, Asian, Italian',\n",
       " ' Italian, Continental',\n",
       " ' Chinese, North Indian',\n",
       " ' North Indian, Chinese',\n",
       " ' North Indian, Italian',\n",
       " ' North Indian',\n",
       " ' North Indian',\n",
       " ' North Indian, Mughlai']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuisine = []\n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    cuisine.append(i.text.split('|')[1])\n",
    "cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a4db6077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Location</th>\n",
       "      <th>Image url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>4.3</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Restaurant Name                        Cuisine Ratings  \\\n",
       "0                   Castle Barbeque          Chinese, North Indian     4.1   \n",
       "1                   Jungle Jamboree   North Indian, Asian, Italian     3.9   \n",
       "2                        Cafe Knosh           Italian, Continental     4.3   \n",
       "3                   Castle Barbeque          Chinese, North Indian     3.9   \n",
       "4              The Barbeque Company          North Indian, Chinese     3.9   \n",
       "5                       India Grill          North Indian, Italian     3.9   \n",
       "6                    Delhi Barbeque                   North Indian     3.6   \n",
       "7  The Monarch - Bar Be Que Village                   North Indian     3.8   \n",
       "8                 Indian Grill Room          North Indian, Mughlai     4.3   \n",
       "\n",
       "                                            Location  \\\n",
       "0                     Connaught Place, Central Delhi   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi   \n",
       "2  The Leela Ambience Convention Hotel,Shahdara, ...   \n",
       "3             Pacific Mall,Tagore Garden, West Delhi   \n",
       "4                 Gardens Galleria,Sector 38A, Noida   \n",
       "5               Hilton Garden Inn,Saket, South Delhi   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon   \n",
       "\n",
       "                                           Image url  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'Restaurant Name':rname, 'Cuisine':cuisine ,'Ratings': rating1, 'Location':loc, 'Image url':img})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40b8e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
